{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import librosa as lb\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "#import splitfolders\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from pyAudioAnalysis import audioBasicIO as aIO\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPooling1D, Activation, Permute, Dense, BatchNormalization, Flatten, LSTM, Bidirectional, Dropout, Masking, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = pd.read_csv('file_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>crack_wheez</th>\n",
       "      <th>fname_cycle</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_0.wav</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>0.579</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_1.wav</td>\n",
       "      <td>1.871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>2.450</td>\n",
       "      <td>3.893</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_2.wav</td>\n",
       "      <td>1.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>3.893</td>\n",
       "      <td>5.793</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_3.wav</td>\n",
       "      <td>1.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>5.793</td>\n",
       "      <td>7.521</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_4.wav</td>\n",
       "      <td>1.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>11.721</td>\n",
       "      <td>13.693</td>\n",
       "      <td>1</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_6.wav</td>\n",
       "      <td>1.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>13.693</td>\n",
       "      <td>15.536</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_7.wav</td>\n",
       "      <td>1.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>15.536</td>\n",
       "      <td>17.493</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_8.wav</td>\n",
       "      <td>1.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>17.493</td>\n",
       "      <td>19.436</td>\n",
       "      <td>1</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_9.wav</td>\n",
       "      <td>1.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6737</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>19.436</td>\n",
       "      <td>19.979</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_10.wav</td>\n",
       "      <td>0.543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6738 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fname   start     end  crack_wheez  \\\n",
       "0     101_1b1_Al_sc_Meditron   0.036   0.579            0   \n",
       "1     101_1b1_Al_sc_Meditron   0.579   2.450            0   \n",
       "2     101_1b1_Al_sc_Meditron   2.450   3.893            0   \n",
       "3     101_1b1_Al_sc_Meditron   3.893   5.793            0   \n",
       "4     101_1b1_Al_sc_Meditron   5.793   7.521            0   \n",
       "...                      ...     ...     ...          ...   \n",
       "6733  226_1b1_Pl_sc_LittC2SE  11.721  13.693            1   \n",
       "6734  226_1b1_Pl_sc_LittC2SE  13.693  15.536            0   \n",
       "6735  226_1b1_Pl_sc_LittC2SE  15.536  17.493            0   \n",
       "6736  226_1b1_Pl_sc_LittC2SE  17.493  19.436            1   \n",
       "6737  226_1b1_Pl_sc_LittC2SE  19.436  19.979            0   \n",
       "\n",
       "                        fname_cycle    len  \n",
       "0      101_1b1_Al_sc_Meditron_0.wav  0.543  \n",
       "1      101_1b1_Al_sc_Meditron_1.wav  1.871  \n",
       "2      101_1b1_Al_sc_Meditron_2.wav  1.443  \n",
       "3      101_1b1_Al_sc_Meditron_3.wav  1.900  \n",
       "4      101_1b1_Al_sc_Meditron_4.wav  1.728  \n",
       "...                             ...    ...  \n",
       "6733   226_1b1_Pl_sc_LittC2SE_6.wav  1.972  \n",
       "6734   226_1b1_Pl_sc_LittC2SE_7.wav  1.843  \n",
       "6735   226_1b1_Pl_sc_LittC2SE_8.wav  1.957  \n",
       "6736   226_1b1_Pl_sc_LittC2SE_9.wav  1.943  \n",
       "6737  226_1b1_Pl_sc_LittC2SE_10.wav  0.543  \n",
       "\n",
       "[6738 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define LSTM model with skip connection\n",
    "def LSTM():\n",
    "    N_CLASSES=4\n",
    "\n",
    "    i = layers.Input(shape=(20, 79), name='input')\n",
    "    x = layers.Masking()(i)\n",
    "    x = layers.BatchNormalization(name='batch_norm')(x)\n",
    "    x = layers.Permute((2,1), name='permute')(x)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.5, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=regularizers.l2(0.001),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"long_short_term_memory\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 20, 79)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking_4 (Masking)             (None, 20, 79)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_norm (BatchNormalization) (None, 20, 79)       316         masking_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 79, 20)       0           batch_norm[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "td_dense_tanh (TimeDistributed) (None, 79, 64)       1344        permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_lstm (Bidirection (None, 79, 256)      197632      td_dense_tanh[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "skip_connection (Concatenate)   (None, 79, 320)      0           td_dense_tanh[0][0]              \n",
      "                                                                 bidirectional_lstm[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_relu (Dense)            (None, 79, 64)       20544       skip_connection[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1d (MaxPooling1D)      (None, 39, 64)       0           dense_1_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_relu (Dense)            (None, 39, 32)       2080        max_pool_1d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1248)         0           dense_2_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1248)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_relu (Dense)            (None, 32)           39968       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 4)            132         dense_3_relu[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 262,016\n",
      "Trainable params: 261,858\n",
      "Non-trainable params: 158\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_df, test_df = train_test_split(file_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>crack_wheez</th>\n",
       "      <th>fname_cycle</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>172_1b3_Pr_mc_AKGC417L</td>\n",
       "      <td>17.571</td>\n",
       "      <td>19.975</td>\n",
       "      <td>1</td>\n",
       "      <td>172_1b3_Pr_mc_AKGC417L_6.wav</td>\n",
       "      <td>2.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>152_1b1_Al_sc_Meditron</td>\n",
       "      <td>11.279</td>\n",
       "      <td>14.507</td>\n",
       "      <td>0</td>\n",
       "      <td>152_1b1_Al_sc_Meditron_4.wav</td>\n",
       "      <td>3.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>120_1b1_Pr_sc_Meditron</td>\n",
       "      <td>53.735</td>\n",
       "      <td>57.214</td>\n",
       "      <td>0</td>\n",
       "      <td>120_1b1_Pr_sc_Meditron_17.wav</td>\n",
       "      <td>3.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>130_2p5_Tc_mc_AKGC417L</td>\n",
       "      <td>15.978</td>\n",
       "      <td>17.937</td>\n",
       "      <td>1</td>\n",
       "      <td>130_2p5_Tc_mc_AKGC417L_8.wav</td>\n",
       "      <td>1.959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>158_1b3_Ar_mc_LittC2SE</td>\n",
       "      <td>12.364</td>\n",
       "      <td>15.021</td>\n",
       "      <td>1</td>\n",
       "      <td>158_1b3_Ar_mc_LittC2SE_7.wav</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>188_1b1_Ar_sc_Meditron</td>\n",
       "      <td>16.421</td>\n",
       "      <td>17.607</td>\n",
       "      <td>0</td>\n",
       "      <td>188_1b1_Ar_sc_Meditron_14.wav</td>\n",
       "      <td>1.186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>159_1b1_Al_sc_Meditron</td>\n",
       "      <td>4.693</td>\n",
       "      <td>6.493</td>\n",
       "      <td>0</td>\n",
       "      <td>159_1b1_Al_sc_Meditron_3.wav</td>\n",
       "      <td>1.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>133_3p2_Ar_mc_AKGC417L</td>\n",
       "      <td>0.851</td>\n",
       "      <td>2.197</td>\n",
       "      <td>0</td>\n",
       "      <td>133_3p2_Ar_mc_AKGC417L_0.wav</td>\n",
       "      <td>1.346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>151_3p2_Pl_mc_AKGC417L</td>\n",
       "      <td>10.860</td>\n",
       "      <td>14.232</td>\n",
       "      <td>1</td>\n",
       "      <td>151_3p2_Pl_mc_AKGC417L_3.wav</td>\n",
       "      <td>3.372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>154_2b4_Al_mc_AKGC417L</td>\n",
       "      <td>11.580</td>\n",
       "      <td>14.072</td>\n",
       "      <td>1</td>\n",
       "      <td>154_2b4_Al_mc_AKGC417L_4.wav</td>\n",
       "      <td>2.492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5390 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fname   start     end  crack_wheez  \\\n",
       "3943  172_1b3_Pr_mc_AKGC417L  17.571  19.975            1   \n",
       "2632  152_1b1_Al_sc_Meditron  11.279  14.507            0   \n",
       "828   120_1b1_Pr_sc_Meditron  53.735  57.214            0   \n",
       "1371  130_2p5_Tc_mc_AKGC417L  15.978  17.937            1   \n",
       "3051  158_1b3_Ar_mc_LittC2SE  12.364  15.021            1   \n",
       "...                      ...     ...     ...          ...   \n",
       "4931  188_1b1_Ar_sc_Meditron  16.421  17.607            0   \n",
       "3264  159_1b1_Al_sc_Meditron   4.693   6.493            0   \n",
       "1653  133_3p2_Ar_mc_AKGC417L   0.851   2.197            0   \n",
       "2607  151_3p2_Pl_mc_AKGC417L  10.860  14.232            1   \n",
       "2732  154_2b4_Al_mc_AKGC417L  11.580  14.072            1   \n",
       "\n",
       "                        fname_cycle    len  \n",
       "3943   172_1b3_Pr_mc_AKGC417L_6.wav  2.404  \n",
       "2632   152_1b1_Al_sc_Meditron_4.wav  3.228  \n",
       "828   120_1b1_Pr_sc_Meditron_17.wav  3.479  \n",
       "1371   130_2p5_Tc_mc_AKGC417L_8.wav  1.959  \n",
       "3051   158_1b3_Ar_mc_LittC2SE_7.wav  2.657  \n",
       "...                             ...    ...  \n",
       "4931  188_1b1_Ar_sc_Meditron_14.wav  1.186  \n",
       "3264   159_1b1_Al_sc_Meditron_3.wav  1.800  \n",
       "1653   133_3p2_Ar_mc_AKGC417L_0.wav  1.346  \n",
       "2607   151_3p2_Pl_mc_AKGC417L_3.wav  3.372  \n",
       "2732   154_2b4_Al_mc_AKGC417L_4.wav  2.492  \n",
       "\n",
       "[5390 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset index\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set maxpad length as 79 <--(Sampling rate*5s)/256(hop length)\n",
    "def build_feat(df):\n",
    "    X = []\n",
    "    Y = []\n",
    "    max_pad_len = 79\n",
    "    for i in tqdm(range(len(df))):\n",
    "        file = df.iloc[i].fname_cycle\n",
    "        label = df.iloc[i].crack_wheez\n",
    "        wav,  rate = lb.load('Breath_cycles/'+ file, sr=None)\n",
    "        #limit the length of samples to only 6s (6*4000)\n",
    "        if wav.shape[0] > 20000:\n",
    "            wav = wav[0:20000]\n",
    "        X_sample = lb.feature.mfcc(wav, sr=rate, n_fft=512,  win_length=400, n_mfcc=20, hop_length = 256, n_mels = 128, fmin = 100, fmax = 1800)\n",
    "        pad_width = max_pad_len - X_sample.shape[1]\n",
    "        X_sample = np.pad(X_sample, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        X.append(X_sample)\n",
    "        Y.append(label)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5390/5390 [01:09<00:00, 77.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#Extract features for training data\n",
    "X_, y_ = build_feat(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5390, 20, 79)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1348/1348 [00:08<00:00, 162.61it/s]\n"
     ]
    }
   ],
   "source": [
    "#Extract feature for testing data\n",
    "X_val, y_val = build_feat(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert labels into one hot vectors\n",
    "y_tr_cat= to_categorical(y_, num_classes=4)\n",
    "y_val_cat= to_categorical(y_val, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/014544907/anaconda3/envs/master_project/lib/python3.8/site-packages/sklearn/utils/validation.py:67: FutureWarning: Pass classes=[0 1 2 3], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    }
   ],
   "source": [
    "#Compute class weight for handling unbalanced classes\n",
    "#https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#class_weights\n",
    "class_weight = compute_class_weight('balanced', np.unique(y_), y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47868561, 0.9001336 , 1.9962963 , 3.34367246])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: class_weight[0], 1: class_weight[1], 2: class_weight[2], 3: class_weight[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join('logs', 'log_history_5s.csv')\n",
    "model = LSTM()\n",
    "#Save model checkpoints\n",
    "cp = ModelCheckpoint('models/lstm_5s.h5', monitor='val_accuracy',  save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch', verbose=1)\n",
    "csv_logger = CSVLogger(csv_path, append=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1537 - accuracy: 0.5139\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.52151, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 46s 539ms/step - loss: 1.1537 - accuracy: 0.5139 - val_loss: 1.1418 - val_accuracy: 0.5215\n",
      "Epoch 2/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.1089 - accuracy: 0.5323\n",
      "Epoch 00002: val_accuracy improved from 0.52151 to 0.52374, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 1.1089 - accuracy: 0.5323 - val_loss: 1.1130 - val_accuracy: 0.5237\n",
      "Epoch 3/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0854 - accuracy: 0.5417\n",
      "Epoch 00003: val_accuracy improved from 0.52374 to 0.54303, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 41s 480ms/step - loss: 1.0854 - accuracy: 0.5417 - val_loss: 1.0723 - val_accuracy: 0.5430\n",
      "Epoch 4/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0652 - accuracy: 0.5501\n",
      "Epoch 00004: val_accuracy did not improve from 0.54303\n",
      "85/85 [==============================] - 41s 482ms/step - loss: 1.0652 - accuracy: 0.5501 - val_loss: 1.0841 - val_accuracy: 0.5356\n",
      "Epoch 5/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0480 - accuracy: 0.5540\n",
      "Epoch 00005: val_accuracy improved from 0.54303 to 0.54970, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 504ms/step - loss: 1.0480 - accuracy: 0.5540 - val_loss: 1.0588 - val_accuracy: 0.5497\n",
      "Epoch 6/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0329 - accuracy: 0.5659\n",
      "Epoch 00006: val_accuracy did not improve from 0.54970\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 1.0329 - accuracy: 0.5659 - val_loss: 1.0562 - val_accuracy: 0.5482\n",
      "Epoch 7/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0209 - accuracy: 0.5718\n",
      "Epoch 00007: val_accuracy improved from 0.54970 to 0.56454, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 44s 514ms/step - loss: 1.0209 - accuracy: 0.5718 - val_loss: 1.0372 - val_accuracy: 0.5645\n",
      "Epoch 8/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0101 - accuracy: 0.5748\n",
      "Epoch 00008: val_accuracy improved from 0.56454 to 0.57196, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 44s 514ms/step - loss: 1.0101 - accuracy: 0.5748 - val_loss: 1.0223 - val_accuracy: 0.5720\n",
      "Epoch 9/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 1.0002 - accuracy: 0.5787\n",
      "Epoch 00009: val_accuracy improved from 0.57196 to 0.57418, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 510ms/step - loss: 1.0002 - accuracy: 0.5787 - val_loss: 1.0008 - val_accuracy: 0.5742\n",
      "Epoch 10/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9865 - accuracy: 0.5859\n",
      "Epoch 00010: val_accuracy improved from 0.57418 to 0.58605, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.9865 - accuracy: 0.5859 - val_loss: 0.9895 - val_accuracy: 0.5861\n",
      "Epoch 11/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9663 - accuracy: 0.5911\n",
      "Epoch 00011: val_accuracy improved from 0.58605 to 0.60163, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 508ms/step - loss: 0.9663 - accuracy: 0.5911 - val_loss: 0.9954 - val_accuracy: 0.6016\n",
      "Epoch 12/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9601 - accuracy: 0.6030\n",
      "Epoch 00012: val_accuracy did not improve from 0.60163\n",
      "85/85 [==============================] - 43s 501ms/step - loss: 0.9601 - accuracy: 0.6030 - val_loss: 0.9902 - val_accuracy: 0.5883\n",
      "Epoch 13/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9417 - accuracy: 0.6059\n",
      "Epoch 00013: val_accuracy did not improve from 0.60163\n",
      "85/85 [==============================] - 42s 493ms/step - loss: 0.9417 - accuracy: 0.6059 - val_loss: 0.9867 - val_accuracy: 0.5972\n",
      "Epoch 14/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9186 - accuracy: 0.6186\n",
      "Epoch 00014: val_accuracy improved from 0.60163 to 0.60534, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 501ms/step - loss: 0.9186 - accuracy: 0.6186 - val_loss: 0.9561 - val_accuracy: 0.6053\n",
      "Epoch 15/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.9147 - accuracy: 0.6237\n",
      "Epoch 00015: val_accuracy improved from 0.60534 to 0.60905, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 44s 516ms/step - loss: 0.9147 - accuracy: 0.6237 - val_loss: 0.9536 - val_accuracy: 0.6091\n",
      "Epoch 16/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8936 - accuracy: 0.6360\n",
      "Epoch 00016: val_accuracy did not improve from 0.60905\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.8936 - accuracy: 0.6360 - val_loss: 0.9369 - val_accuracy: 0.6068\n",
      "Epoch 17/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8786 - accuracy: 0.6373\n",
      "Epoch 00017: val_accuracy improved from 0.60905 to 0.61350, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 45s 530ms/step - loss: 0.8786 - accuracy: 0.6373 - val_loss: 0.9358 - val_accuracy: 0.6135\n",
      "Epoch 18/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8623 - accuracy: 0.6412\n",
      "Epoch 00018: val_accuracy improved from 0.61350 to 0.63056, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 42s 490ms/step - loss: 0.8623 - accuracy: 0.6412 - val_loss: 0.9103 - val_accuracy: 0.6306\n",
      "Epoch 19/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.6581\n",
      "Epoch 00019: val_accuracy did not improve from 0.63056\n",
      "85/85 [==============================] - 41s 481ms/step - loss: 0.8398 - accuracy: 0.6581 - val_loss: 0.9165 - val_accuracy: 0.6239\n",
      "Epoch 20/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8383 - accuracy: 0.6610\n",
      "Epoch 00020: val_accuracy did not improve from 0.63056\n",
      "85/85 [==============================] - 43s 507ms/step - loss: 0.8383 - accuracy: 0.6610 - val_loss: 0.9073 - val_accuracy: 0.6291\n",
      "Epoch 21/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.8158 - accuracy: 0.6735\n",
      "Epoch 00021: val_accuracy improved from 0.63056 to 0.63353, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 44s 518ms/step - loss: 0.8158 - accuracy: 0.6735 - val_loss: 0.8944 - val_accuracy: 0.6335\n",
      "Epoch 22/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7876 - accuracy: 0.6855\n",
      "Epoch 00022: val_accuracy improved from 0.63353 to 0.64169, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 505ms/step - loss: 0.7876 - accuracy: 0.6855 - val_loss: 0.8861 - val_accuracy: 0.6417\n",
      "Epoch 23/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7627 - accuracy: 0.6946\n",
      "Epoch 00023: val_accuracy improved from 0.64169 to 0.64688, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 42s 495ms/step - loss: 0.7627 - accuracy: 0.6946 - val_loss: 0.8934 - val_accuracy: 0.6469\n",
      "Epoch 24/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7529 - accuracy: 0.6955\n",
      "Epoch 00024: val_accuracy improved from 0.64688 to 0.66024, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 501ms/step - loss: 0.7529 - accuracy: 0.6955 - val_loss: 0.8595 - val_accuracy: 0.6602\n",
      "Epoch 25/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7356 - accuracy: 0.7058\n",
      "Epoch 00025: val_accuracy did not improve from 0.66024\n",
      "85/85 [==============================] - 44s 519ms/step - loss: 0.7356 - accuracy: 0.7058 - val_loss: 0.8509 - val_accuracy: 0.6595\n",
      "Epoch 26/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.7021 - accuracy: 0.7134\n",
      "Epoch 00026: val_accuracy did not improve from 0.66024\n",
      "85/85 [==============================] - 42s 489ms/step - loss: 0.7021 - accuracy: 0.7134 - val_loss: 0.8818 - val_accuracy: 0.6506\n",
      "Epoch 27/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6949 - accuracy: 0.7234\n",
      "Epoch 00027: val_accuracy did not improve from 0.66024\n",
      "85/85 [==============================] - 42s 492ms/step - loss: 0.6949 - accuracy: 0.7234 - val_loss: 0.9077 - val_accuracy: 0.6602\n",
      "Epoch 28/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6575 - accuracy: 0.7423\n",
      "Epoch 00028: val_accuracy did not improve from 0.66024\n",
      "85/85 [==============================] - 43s 505ms/step - loss: 0.6575 - accuracy: 0.7423 - val_loss: 0.8524 - val_accuracy: 0.6588\n",
      "Epoch 29/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6565 - accuracy: 0.7382\n",
      "Epoch 00029: val_accuracy improved from 0.66024 to 0.66988, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 44s 512ms/step - loss: 0.6565 - accuracy: 0.7382 - val_loss: 0.8611 - val_accuracy: 0.6699\n",
      "Epoch 30/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.7434\n",
      "Epoch 00030: val_accuracy did not improve from 0.66988\n",
      "85/85 [==============================] - 45s 524ms/step - loss: 0.6449 - accuracy: 0.7434 - val_loss: 0.8740 - val_accuracy: 0.6610\n",
      "Epoch 31/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.6271 - accuracy: 0.7577\n",
      "Epoch 00031: val_accuracy improved from 0.66988 to 0.68249, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 43s 506ms/step - loss: 0.6271 - accuracy: 0.7577 - val_loss: 0.8406 - val_accuracy: 0.6825\n",
      "Epoch 32/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5951 - accuracy: 0.7690\n",
      "Epoch 00032: val_accuracy did not improve from 0.68249\n",
      "85/85 [==============================] - 36s 422ms/step - loss: 0.5951 - accuracy: 0.7690 - val_loss: 0.8711 - val_accuracy: 0.6728\n",
      "Epoch 33/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5787 - accuracy: 0.7757\n",
      "Epoch 00033: val_accuracy improved from 0.68249 to 0.68991, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 34s 400ms/step - loss: 0.5787 - accuracy: 0.7757 - val_loss: 0.8449 - val_accuracy: 0.6899\n",
      "Epoch 34/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.7857\n",
      "Epoch 00034: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 30s 347ms/step - loss: 0.5513 - accuracy: 0.7857 - val_loss: 0.8849 - val_accuracy: 0.6699\n",
      "Epoch 35/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5468 - accuracy: 0.7920\n",
      "Epoch 00035: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 30s 352ms/step - loss: 0.5468 - accuracy: 0.7920 - val_loss: 0.8601 - val_accuracy: 0.6832\n",
      "Epoch 36/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5249 - accuracy: 0.7998\n",
      "Epoch 00036: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 37s 437ms/step - loss: 0.5249 - accuracy: 0.7998 - val_loss: 0.8583 - val_accuracy: 0.6795\n",
      "Epoch 37/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8067\n",
      "Epoch 00037: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 39s 460ms/step - loss: 0.5169 - accuracy: 0.8067 - val_loss: 0.8716 - val_accuracy: 0.6840\n",
      "Epoch 38/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.8071\n",
      "Epoch 00038: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 40s 468ms/step - loss: 0.5042 - accuracy: 0.8071 - val_loss: 0.9011 - val_accuracy: 0.6766\n",
      "Epoch 39/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4975 - accuracy: 0.8163\n",
      "Epoch 00039: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 40s 467ms/step - loss: 0.4975 - accuracy: 0.8163 - val_loss: 0.8936 - val_accuracy: 0.6766\n",
      "Epoch 40/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4794 - accuracy: 0.8210\n",
      "Epoch 00040: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 39s 458ms/step - loss: 0.4794 - accuracy: 0.8210 - val_loss: 0.8705 - val_accuracy: 0.6832\n",
      "Epoch 41/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.8176\n",
      "Epoch 00041: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 50s 585ms/step - loss: 0.4668 - accuracy: 0.8176 - val_loss: 0.9123 - val_accuracy: 0.6840\n",
      "Epoch 42/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4354 - accuracy: 0.8395\n",
      "Epoch 00042: val_accuracy did not improve from 0.68991\n",
      "85/85 [==============================] - 61s 722ms/step - loss: 0.4354 - accuracy: 0.8395 - val_loss: 0.8803 - val_accuracy: 0.6855\n",
      "Epoch 43/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4292 - accuracy: 0.8423\n",
      "Epoch 00043: val_accuracy improved from 0.68991 to 0.69881, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 65s 769ms/step - loss: 0.4292 - accuracy: 0.8423 - val_loss: 0.8923 - val_accuracy: 0.6988\n",
      "Epoch 44/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4320 - accuracy: 0.8425\n",
      "Epoch 00044: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 40s 472ms/step - loss: 0.4320 - accuracy: 0.8425 - val_loss: 0.8861 - val_accuracy: 0.6958\n",
      "Epoch 45/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.8468\n",
      "Epoch 00045: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 39s 464ms/step - loss: 0.4164 - accuracy: 0.8468 - val_loss: 0.9444 - val_accuracy: 0.6795\n",
      "Epoch 46/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.4095 - accuracy: 0.8510\n",
      "Epoch 00046: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 39s 465ms/step - loss: 0.4095 - accuracy: 0.8510 - val_loss: 0.9352 - val_accuracy: 0.6840\n",
      "Epoch 47/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3753 - accuracy: 0.8694\n",
      "Epoch 00047: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 41s 479ms/step - loss: 0.3753 - accuracy: 0.8694 - val_loss: 0.9732 - val_accuracy: 0.6936\n",
      "Epoch 48/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3621 - accuracy: 0.8675\n",
      "Epoch 00048: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 47s 552ms/step - loss: 0.3621 - accuracy: 0.8675 - val_loss: 0.8858 - val_accuracy: 0.6958\n",
      "Epoch 49/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3633 - accuracy: 0.8688\n",
      "Epoch 00049: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 33s 383ms/step - loss: 0.3633 - accuracy: 0.8688 - val_loss: 0.9745 - val_accuracy: 0.6914\n",
      "Epoch 50/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.8774\n",
      "Epoch 00050: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 29s 339ms/step - loss: 0.3527 - accuracy: 0.8774 - val_loss: 0.9383 - val_accuracy: 0.6936\n",
      "Epoch 51/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3577 - accuracy: 0.8761\n",
      "Epoch 00051: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 36s 420ms/step - loss: 0.3577 - accuracy: 0.8761 - val_loss: 0.9922 - val_accuracy: 0.6869\n",
      "Epoch 52/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3341 - accuracy: 0.8794\n",
      "Epoch 00052: val_accuracy did not improve from 0.69881\n",
      "85/85 [==============================] - 39s 453ms/step - loss: 0.3341 - accuracy: 0.8794 - val_loss: 0.9832 - val_accuracy: 0.6877\n",
      "Epoch 53/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8763\n",
      "Epoch 00053: val_accuracy improved from 0.69881 to 0.70030, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 40s 474ms/step - loss: 0.3493 - accuracy: 0.8763 - val_loss: 0.9335 - val_accuracy: 0.7003\n",
      "Epoch 54/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3043 - accuracy: 0.8957\n",
      "Epoch 00054: val_accuracy did not improve from 0.70030\n",
      "85/85 [==============================] - 40s 465ms/step - loss: 0.3043 - accuracy: 0.8957 - val_loss: 0.9944 - val_accuracy: 0.6899\n",
      "Epoch 55/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.3117 - accuracy: 0.8931\n",
      "Epoch 00055: val_accuracy did not improve from 0.70030\n",
      "85/85 [==============================] - 45s 524ms/step - loss: 0.3117 - accuracy: 0.8931 - val_loss: 0.9849 - val_accuracy: 0.7003\n",
      "Epoch 56/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2805 - accuracy: 0.9037\n",
      "Epoch 00056: val_accuracy did not improve from 0.70030\n",
      "85/85 [==============================] - 40s 471ms/step - loss: 0.2805 - accuracy: 0.9037 - val_loss: 1.0230 - val_accuracy: 0.6951\n",
      "Epoch 57/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2852 - accuracy: 0.9039\n",
      "Epoch 00057: val_accuracy improved from 0.70030 to 0.70772, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 40s 465ms/step - loss: 0.2852 - accuracy: 0.9039 - val_loss: 0.9612 - val_accuracy: 0.7077\n",
      "Epoch 58/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2999 - accuracy: 0.8976\n",
      "Epoch 00058: val_accuracy did not improve from 0.70772\n",
      "85/85 [==============================] - 40s 473ms/step - loss: 0.2999 - accuracy: 0.8976 - val_loss: 0.9857 - val_accuracy: 0.6973\n",
      "Epoch 59/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2698 - accuracy: 0.9091\n",
      "Epoch 00059: val_accuracy improved from 0.70772 to 0.71365, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 72s 842ms/step - loss: 0.2698 - accuracy: 0.9091 - val_loss: 1.0265 - val_accuracy: 0.7136\n",
      "Epoch 60/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2787 - accuracy: 0.9071\n",
      "Epoch 00060: val_accuracy did not improve from 0.71365\n",
      "85/85 [==============================] - 94s 1s/step - loss: 0.2787 - accuracy: 0.9071 - val_loss: 1.0411 - val_accuracy: 0.7010\n",
      "Epoch 61/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.9074\n",
      "Epoch 00061: val_accuracy did not improve from 0.71365\n",
      "85/85 [==============================] - 97s 1s/step - loss: 0.2679 - accuracy: 0.9074 - val_loss: 1.0652 - val_accuracy: 0.6929\n",
      "Epoch 62/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2577 - accuracy: 0.9122\n",
      "Epoch 00062: val_accuracy did not improve from 0.71365\n",
      "85/85 [==============================] - 96s 1s/step - loss: 0.2577 - accuracy: 0.9122 - val_loss: 0.9934 - val_accuracy: 0.7077\n",
      "Epoch 63/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.9291\n",
      "Epoch 00063: val_accuracy improved from 0.71365 to 0.71736, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 94s 1s/step - loss: 0.2298 - accuracy: 0.9291 - val_loss: 1.0266 - val_accuracy: 0.7174\n",
      "Epoch 64/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.9262\n",
      "Epoch 00064: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 106s 1s/step - loss: 0.2276 - accuracy: 0.9262 - val_loss: 1.0158 - val_accuracy: 0.7144\n",
      "Epoch 65/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9306\n",
      "Epoch 00065: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 95s 1s/step - loss: 0.2217 - accuracy: 0.9306 - val_loss: 1.0115 - val_accuracy: 0.7085\n",
      "Epoch 66/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9254\n",
      "Epoch 00066: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 84s 992ms/step - loss: 0.2274 - accuracy: 0.9254 - val_loss: 1.0646 - val_accuracy: 0.7085\n",
      "Epoch 67/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9260\n",
      "Epoch 00067: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 86s 1s/step - loss: 0.2273 - accuracy: 0.9260 - val_loss: 1.0359 - val_accuracy: 0.6966\n",
      "Epoch 68/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.9276\n",
      "Epoch 00068: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 75s 879ms/step - loss: 0.2301 - accuracy: 0.9276 - val_loss: 1.0561 - val_accuracy: 0.7025\n",
      "Epoch 69/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.9267\n",
      "Epoch 00069: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 105s 1s/step - loss: 0.2304 - accuracy: 0.9267 - val_loss: 1.0214 - val_accuracy: 0.7047\n",
      "Epoch 70/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9319\n",
      "Epoch 00070: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 86s 1s/step - loss: 0.2152 - accuracy: 0.9319 - val_loss: 1.0280 - val_accuracy: 0.7033\n",
      "Epoch 71/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1979 - accuracy: 0.9367\n",
      "Epoch 00071: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 85s 1s/step - loss: 0.1979 - accuracy: 0.9367 - val_loss: 1.0528 - val_accuracy: 0.7092\n",
      "Epoch 72/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.9414\n",
      "Epoch 00072: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 87s 1s/step - loss: 0.1992 - accuracy: 0.9414 - val_loss: 1.0025 - val_accuracy: 0.7136\n",
      "Epoch 73/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1996 - accuracy: 0.9384\n",
      "Epoch 00073: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 87s 1s/step - loss: 0.1996 - accuracy: 0.9384 - val_loss: 1.0447 - val_accuracy: 0.7159\n",
      "Epoch 74/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2060 - accuracy: 0.9403\n",
      "Epoch 00074: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 86s 1s/step - loss: 0.2060 - accuracy: 0.9403 - val_loss: 1.0182 - val_accuracy: 0.7092\n",
      "Epoch 75/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2073 - accuracy: 0.9334\n",
      "Epoch 00075: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 84s 992ms/step - loss: 0.2073 - accuracy: 0.9334 - val_loss: 1.1320 - val_accuracy: 0.7070\n",
      "Epoch 76/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9401\n",
      "Epoch 00076: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 85s 1s/step - loss: 0.1887 - accuracy: 0.9401 - val_loss: 1.0656 - val_accuracy: 0.7055\n",
      "Epoch 77/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.2766 - accuracy: 0.9071\n",
      "Epoch 00077: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 82s 969ms/step - loss: 0.2766 - accuracy: 0.9071 - val_loss: 1.0826 - val_accuracy: 0.7055\n",
      "Epoch 78/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1968 - accuracy: 0.9384\n",
      "Epoch 00078: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 48s 559ms/step - loss: 0.1968 - accuracy: 0.9384 - val_loss: 1.0715 - val_accuracy: 0.7099\n",
      "Epoch 79/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.9482\n",
      "Epoch 00079: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 48s 569ms/step - loss: 0.1740 - accuracy: 0.9482 - val_loss: 1.1516 - val_accuracy: 0.7018\n",
      "Epoch 80/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1655 - accuracy: 0.9499\n",
      "Epoch 00080: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 46s 536ms/step - loss: 0.1655 - accuracy: 0.9499 - val_loss: 1.1841 - val_accuracy: 0.6803\n",
      "Epoch 81/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9518\n",
      "Epoch 00081: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 49s 574ms/step - loss: 0.1630 - accuracy: 0.9518 - val_loss: 1.1245 - val_accuracy: 0.7136\n",
      "Epoch 82/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1614 - accuracy: 0.9534\n",
      "Epoch 00082: val_accuracy did not improve from 0.71736\n",
      "85/85 [==============================] - 45s 535ms/step - loss: 0.1614 - accuracy: 0.9534 - val_loss: 1.0968 - val_accuracy: 0.6966\n",
      "Epoch 83/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1547 - accuracy: 0.9551\n",
      "Epoch 00083: val_accuracy improved from 0.71736 to 0.71810, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 47s 557ms/step - loss: 0.1547 - accuracy: 0.9551 - val_loss: 1.1738 - val_accuracy: 0.7181\n",
      "Epoch 84/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1997 - accuracy: 0.9314\n",
      "Epoch 00084: val_accuracy did not improve from 0.71810\n",
      "85/85 [==============================] - 55s 650ms/step - loss: 0.1997 - accuracy: 0.9314 - val_loss: 1.1136 - val_accuracy: 0.7062\n",
      "Epoch 85/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9456\n",
      "Epoch 00085: val_accuracy did not improve from 0.71810\n",
      "85/85 [==============================] - 55s 649ms/step - loss: 0.1744 - accuracy: 0.9456 - val_loss: 1.1337 - val_accuracy: 0.7151\n",
      "Epoch 86/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9532\n",
      "Epoch 00086: val_accuracy improved from 0.71810 to 0.71884, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 26s 303ms/step - loss: 0.1593 - accuracy: 0.9532 - val_loss: 1.0843 - val_accuracy: 0.7188\n",
      "Epoch 87/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1390 - accuracy: 0.9625\n",
      "Epoch 00087: val_accuracy did not improve from 0.71884\n",
      "85/85 [==============================] - 27s 314ms/step - loss: 0.1390 - accuracy: 0.9625 - val_loss: 1.1172 - val_accuracy: 0.7174\n",
      "Epoch 88/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9575\n",
      "Epoch 00088: val_accuracy did not improve from 0.71884\n",
      "85/85 [==============================] - 25s 290ms/step - loss: 0.1497 - accuracy: 0.9575 - val_loss: 1.1176 - val_accuracy: 0.7166\n",
      "Epoch 89/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9631\n",
      "Epoch 00089: val_accuracy improved from 0.71884 to 0.72997, saving model to models/lstm_5s.h5\n",
      "85/85 [==============================] - 28s 325ms/step - loss: 0.1321 - accuracy: 0.9631 - val_loss: 1.1539 - val_accuracy: 0.7300\n",
      "Epoch 90/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1288 - accuracy: 0.9633\n",
      "Epoch 00090: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 31s 365ms/step - loss: 0.1288 - accuracy: 0.9633 - val_loss: 1.1173 - val_accuracy: 0.7159\n",
      "Epoch 91/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1265 - accuracy: 0.9675\n",
      "Epoch 00091: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 29s 338ms/step - loss: 0.1265 - accuracy: 0.9675 - val_loss: 1.1891 - val_accuracy: 0.7062\n",
      "Epoch 92/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9623\n",
      "Epoch 00092: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 29s 338ms/step - loss: 0.1259 - accuracy: 0.9623 - val_loss: 1.2175 - val_accuracy: 0.7062\n",
      "Epoch 93/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1275 - accuracy: 0.9653\n",
      "Epoch 00093: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 29s 340ms/step - loss: 0.1275 - accuracy: 0.9653 - val_loss: 1.2034 - val_accuracy: 0.7174\n",
      "Epoch 94/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1297 - accuracy: 0.9673\n",
      "Epoch 00094: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 35s 415ms/step - loss: 0.1297 - accuracy: 0.9673 - val_loss: 1.1885 - val_accuracy: 0.7055\n",
      "Epoch 95/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1479 - accuracy: 0.9586\n",
      "Epoch 00095: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 60s 706ms/step - loss: 0.1479 - accuracy: 0.9586 - val_loss: 1.1756 - val_accuracy: 0.7085\n",
      "Epoch 96/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9607\n",
      "Epoch 00096: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 45s 533ms/step - loss: 0.1369 - accuracy: 0.9607 - val_loss: 1.1597 - val_accuracy: 0.6981\n",
      "Epoch 97/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1553 - accuracy: 0.9551\n",
      "Epoch 00097: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 41s 488ms/step - loss: 0.1553 - accuracy: 0.9551 - val_loss: 1.1418 - val_accuracy: 0.6973\n",
      "Epoch 98/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1400 - accuracy: 0.9597\n",
      "Epoch 00098: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 46s 542ms/step - loss: 0.1400 - accuracy: 0.9597 - val_loss: 1.1710 - val_accuracy: 0.7174\n",
      "Epoch 99/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1179 - accuracy: 0.9677\n",
      "Epoch 00099: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 40s 475ms/step - loss: 0.1179 - accuracy: 0.9677 - val_loss: 1.2076 - val_accuracy: 0.7114\n",
      "Epoch 100/100\n",
      "85/85 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9670\n",
      "Epoch 00100: val_accuracy did not improve from 0.72997\n",
      "85/85 [==============================] - 46s 536ms/step - loss: 0.1259 - accuracy: 0.9670 - val_loss: 1.1974 - val_accuracy: 0.7174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f473d206970>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model\n",
    "model.fit(X_,y_tr_cat, epochs = 100, workers=4, batch_size = 64, validation_data=(X_val, y_val_cat), callbacks=[csv_logger, cp], verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It can be used to reconstruct the model identically.\n",
    "saved_model = keras.models.load_model(\"models/lstm_5s.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "          None       0.79      0.84      0.82       702\n",
      "       Crackle       0.67      0.70      0.68       350\n",
      "        Wheeze       0.70      0.52      0.60       199\n",
      "Crackle_wheeze       0.52      0.47      0.50        97\n",
      "\n",
      "      accuracy                           0.73      1348\n",
      "     macro avg       0.67      0.63      0.65      1348\n",
      "  weighted avg       0.73      0.73      0.73      1348\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f477152f490>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "matrix_index = [\"None\", \"Crackle\", \"Wheeze\", \"Crackle_wheeze\"]\n",
    "\n",
    "preds = saved_model.predict(X_val)\n",
    "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
    "y_testclass = np.argmax(y_val_cat, axis=1) # true classes\n",
    "\n",
    "cm = confusion_matrix(y_testclass, classpreds)\n",
    "print(classification_report(y_testclass, classpreds, target_names=matrix_index))\n",
    "\n",
    "# Get percentage value for each element of the matrix\n",
    "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "cm_perc = cm / cm_sum.astype(float) * 100\n",
    "annot = np.empty_like(cm).astype(str)\n",
    "nrows, ncols = cm.shape\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "        c = cm[i, j]\n",
    "        p = cm_perc[i, j]\n",
    "        if i == j:\n",
    "            s = cm_sum[i]\n",
    "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "        elif c == 0:\n",
    "            annot[i, j] = ''\n",
    "        else:\n",
    "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "\n",
    "\n",
    "# Display confusion matrix \n",
    "df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "sns.heatmap(df_cm, annot=annot, fmt='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
