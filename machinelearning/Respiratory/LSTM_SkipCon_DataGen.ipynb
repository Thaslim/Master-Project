{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import librosa as lb\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "import splitfolders\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Conv2D, Input, MaxPooling1D, Activation, Permute, Dense, BatchNormalization, Flatten, LSTM, Bidirectional, Dropout, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_data = pd.read_csv('file_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>crack_wheez</th>\n",
       "      <th>fname_cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_0.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>0.579</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_1.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>2.450</td>\n",
       "      <td>3.893</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_2.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>3.893</td>\n",
       "      <td>5.793</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_3.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>5.793</td>\n",
       "      <td>7.521</td>\n",
       "      <td>0</td>\n",
       "      <td>101_1b1_Al_sc_Meditron_4.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6893</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>11.721</td>\n",
       "      <td>13.693</td>\n",
       "      <td>1</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_6.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6894</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>13.693</td>\n",
       "      <td>15.536</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_7.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6895</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>15.536</td>\n",
       "      <td>17.493</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_8.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6896</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>17.493</td>\n",
       "      <td>19.436</td>\n",
       "      <td>1</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_9.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>19.436</td>\n",
       "      <td>19.979</td>\n",
       "      <td>0</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE_10.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6898 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fname   start     end  crack_wheez  \\\n",
       "0     101_1b1_Al_sc_Meditron   0.036   0.579            0   \n",
       "1     101_1b1_Al_sc_Meditron   0.579   2.450            0   \n",
       "2     101_1b1_Al_sc_Meditron   2.450   3.893            0   \n",
       "3     101_1b1_Al_sc_Meditron   3.893   5.793            0   \n",
       "4     101_1b1_Al_sc_Meditron   5.793   7.521            0   \n",
       "...                      ...     ...     ...          ...   \n",
       "6893  226_1b1_Pl_sc_LittC2SE  11.721  13.693            1   \n",
       "6894  226_1b1_Pl_sc_LittC2SE  13.693  15.536            0   \n",
       "6895  226_1b1_Pl_sc_LittC2SE  15.536  17.493            0   \n",
       "6896  226_1b1_Pl_sc_LittC2SE  17.493  19.436            1   \n",
       "6897  226_1b1_Pl_sc_LittC2SE  19.436  19.979            0   \n",
       "\n",
       "                        fname_cycle  \n",
       "0      101_1b1_Al_sc_Meditron_0.wav  \n",
       "1      101_1b1_Al_sc_Meditron_1.wav  \n",
       "2      101_1b1_Al_sc_Meditron_2.wav  \n",
       "3      101_1b1_Al_sc_Meditron_3.wav  \n",
       "4      101_1b1_Al_sc_Meditron_4.wav  \n",
       "...                             ...  \n",
       "6893   226_1b1_Pl_sc_LittC2SE_6.wav  \n",
       "6894   226_1b1_Pl_sc_LittC2SE_7.wav  \n",
       "6895   226_1b1_Pl_sc_LittC2SE_8.wav  \n",
       "6896   226_1b1_Pl_sc_LittC2SE_9.wav  \n",
       "6897  226_1b1_Pl_sc_LittC2SE_10.wav  \n",
       "\n",
       "[6898 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in file_data.iterrows():\n",
    "    if row['crack_wheez'] == 0:\n",
    "        shutil.move('Breath_cycles/'+row['fname_cycle'], 'clean/healthy/')\n",
    "    if row['crack_wheez'] == 1:\n",
    "        shutil.move('Breath_cycles/'+row['fname_cycle'], 'clean/crackle/')\n",
    "    if row['crack_wheez'] == 2:\n",
    "        shutil.move('Breath_cycles/'+row['fname_cycle'], 'clean/wheeze/')\n",
    "    if row['crack_wheez'] == 3:\n",
    "        shutil.move('Breath_cycles/'+row['fname_cycle'], 'clean/both/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define sequence data generator\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, wav_paths, labels, n_classes,\n",
    "                 batch_size=32, shuffle=True, max_pad_len = 94):\n",
    "        self.wav_paths = wav_paths\n",
    "        self.labels = labels\n",
    "        self.n_classes = n_classes\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = True\n",
    "        self.max_pad_len = max_pad_len\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.wav_paths) / self.batch_size))\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        wav_paths = [self.wav_paths[k] for k in indexes]\n",
    "        labels = [self.labels[k] for k in indexes]\n",
    "\n",
    "        # generate a batch of time data\n",
    "        X = np.empty((self.batch_size, 20, 94), dtype=np.float32)\n",
    "        Y = np.empty((self.batch_size, self.n_classes), dtype=np.float32)\n",
    "\n",
    "        for i, (path, label) in enumerate(zip(wav_paths, labels)):\n",
    "            #Load wav file and trim if length is more than 6s\n",
    "            wav,  rate = lb.load(path, sr=None)\n",
    "            if wav.shape[0] > 24000:\n",
    "                wav = wav[0:24000]\n",
    "            #extract mfcc feature\n",
    "            X_sample = lb.feature.mfcc(wav, sr=rate, n_fft=512,  win_length=400, n_mfcc=20, hop_length = 256, n_mels = 128, fmin = 100, fmax = 1800)\n",
    "           #pad zeros to match the max length\n",
    "            pad_width = self.max_pad_len - X_sample.shape[1]\n",
    "            X_sample = np.pad(X_sample, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "            X[i,] = X_sample\n",
    "            Y[i,] = to_categorical(label, num_classes=self.n_classes)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.wav_paths))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define LSTM model with skip connection\n",
    "def LSTM():\n",
    "    N_CLASSES=4\n",
    "\n",
    "    i = layers.Input(shape=(20, 94), name='input')\n",
    "    x = layers.Permute((2,1), name='permute')(i)\n",
    "    s = TimeDistributed(layers.Dense(64, activation='tanh'),\n",
    "                        name='td_dense_tanh')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(128, return_sequences=True),\n",
    "                             name='bidirectional_lstm')(s)\n",
    "    x = layers.concatenate([s, x], axis=2, name='skip_connection')\n",
    "    x = layers.Dense(64, activation='relu', name='dense_1_relu')(x)\n",
    "    x = layers.MaxPooling1D(name='max_pool_1d')(x)\n",
    "    x = layers.Dense(32, activation='relu', name='dense_2_relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dropout(rate=0.2, name='dropout')(x)\n",
    "    x = layers.Dense(32, activation='relu',\n",
    "                         activity_regularizer=regularizers.l2(0.001),\n",
    "                         name='dense_3_relu')(x)\n",
    "    o = layers.Dense(N_CLASSES, activation='softmax', name='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=i, outputs=o, name='long_short_term_memory')\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"long_short_term_memory\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              [(None, 20, 94)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 94, 20)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "td_dense_tanh (TimeDistributed) (None, 94, 64)       1344        permute[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_lstm (Bidirection (None, 94, 256)      197632      td_dense_tanh[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "skip_connection (Concatenate)   (None, 94, 320)      0           td_dense_tanh[0][0]              \n",
      "                                                                 bidirectional_lstm[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1_relu (Dense)            (None, 94, 64)       20544       skip_connection[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pool_1d (MaxPooling1D)      (None, 47, 64)       0           dense_1_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2_relu (Dense)            (None, 47, 32)       2080        max_pool_1d[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 47, 32)       128         dense_2_relu[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1504)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1504)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3_relu (Dense)            (None, 32)           48160       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 4)            132         dense_3_relu[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 270,020\n",
      "Trainable params: 269,956\n",
      "Non-trainable params: 64\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    csv_path = os.path.join('logs', 'log_history.csv')\n",
    "    wav_paths = glob('{}/**'.format('clean/'), recursive=True)\n",
    "    wav_paths = [x.replace(os.sep, '/') for x in wav_paths if '.wav' in x]\n",
    "    classes = sorted(os.listdir('clean/'))\n",
    "    le = LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    labels = [os.path.split(x)[0].split('/')[-1] for x in wav_paths]\n",
    "    labels = le.transform(labels)\n",
    "    # Split data into train and test sets\n",
    "    wav_train, wav_val, label_train, label_val = train_test_split(wav_paths,\n",
    "                                                                  labels,\n",
    "                                                                  test_size=0.1,\n",
    "                                                                  random_state=0)\n",
    "    #Generate train and test data in batches\n",
    "    tg = DataGenerator(wav_train, label_train, 4, batch_size=32)\n",
    "    vg = DataGenerator(wav_val, label_val,  4, batch_size=32)\n",
    "    \n",
    "    model = LSTM()\n",
    "    #Save model checkpoints\n",
    "    cp = ModelCheckpoint('models/lstm.h5', monitor='val_loss',  save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch', verbose=1)\n",
    "    csv_logger = CSVLogger(csv_path, append=False)\n",
    "    #Fit model\n",
    "    model.fit(tg, validation_data=vg, epochs=50, verbose=1, workers=2, callbacks=[csv_logger, cp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 194 steps, validate for 21 steps\n",
      "Epoch 1/50\n",
      "193/194 [============================>.] - ETA: 1s - loss: 1.1660 - accuracy: 0.5115\n",
      "Epoch 00001: val_loss improved from inf to 1.10377, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 248s 1s/step - loss: 1.1663 - accuracy: 0.5113 - val_loss: 1.1038 - val_accuracy: 0.5655\n",
      "Epoch 2/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.1186 - accuracy: 0.5248\n",
      "Epoch 00002: val_loss improved from 1.10377 to 1.08491, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 167s 859ms/step - loss: 1.1189 - accuracy: 0.5242 - val_loss: 1.0849 - val_accuracy: 0.5789\n",
      "Epoch 3/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0891 - accuracy: 0.5452\n",
      "Epoch 00003: val_loss improved from 1.08491 to 1.03096, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 166s 858ms/step - loss: 1.0878 - accuracy: 0.5457 - val_loss: 1.0310 - val_accuracy: 0.5818\n",
      "Epoch 4/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0736 - accuracy: 0.5432\n",
      "Epoch 00004: val_loss did not improve from 1.03096\n",
      "194/194 [==============================] - 149s 767ms/step - loss: 1.0738 - accuracy: 0.5433 - val_loss: 1.2704 - val_accuracy: 0.5670\n",
      "Epoch 5/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0583 - accuracy: 0.5449\n",
      "Epoch 00005: val_loss improved from 1.03096 to 1.02847, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 187s 966ms/step - loss: 1.0581 - accuracy: 0.5451 - val_loss: 1.0285 - val_accuracy: 0.5848\n",
      "Epoch 6/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0365 - accuracy: 0.5583\n",
      "Epoch 00006: val_loss did not improve from 1.02847\n",
      "194/194 [==============================] - 163s 840ms/step - loss: 1.0368 - accuracy: 0.5583 - val_loss: 1.0399 - val_accuracy: 0.5759\n",
      "Epoch 7/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0355 - accuracy: 0.5654\n",
      "Epoch 00007: val_loss did not improve from 1.02847\n",
      "194/194 [==============================] - 164s 845ms/step - loss: 1.0350 - accuracy: 0.5654 - val_loss: 1.0354 - val_accuracy: 0.5729\n",
      "Epoch 8/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 1.0114 - accuracy: 0.5685\n",
      "Epoch 00008: val_loss improved from 1.02847 to 0.99394, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 99s 511ms/step - loss: 1.0112 - accuracy: 0.5686 - val_loss: 0.9939 - val_accuracy: 0.6027\n",
      "Epoch 9/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9829 - accuracy: 0.5848\n",
      "Epoch 00009: val_loss did not improve from 0.99394\n",
      "194/194 [==============================] - 95s 489ms/step - loss: 0.9840 - accuracy: 0.5839 - val_loss: 1.1777 - val_accuracy: 0.5804\n",
      "Epoch 10/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9678 - accuracy: 0.5950\n",
      "Epoch 00010: val_loss did not improve from 0.99394\n",
      "194/194 [==============================] - 77s 398ms/step - loss: 0.9680 - accuracy: 0.5950 - val_loss: 1.0884 - val_accuracy: 0.5491\n",
      "Epoch 11/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9530 - accuracy: 0.6052\n",
      "Epoch 00011: val_loss did not improve from 0.99394\n",
      "194/194 [==============================] - 83s 426ms/step - loss: 0.9532 - accuracy: 0.6057 - val_loss: 1.0158 - val_accuracy: 0.5997\n",
      "Epoch 12/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9281 - accuracy: 0.6106\n",
      "Epoch 00012: val_loss did not improve from 0.99394\n",
      "194/194 [==============================] - 122s 629ms/step - loss: 0.9284 - accuracy: 0.6102 - val_loss: 1.0197 - val_accuracy: 0.6161\n",
      "Epoch 13/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9185 - accuracy: 0.6137\n",
      "Epoch 00013: val_loss did not improve from 0.99394\n",
      "194/194 [==============================] - 131s 676ms/step - loss: 0.9188 - accuracy: 0.6131 - val_loss: 1.1930 - val_accuracy: 0.6086\n",
      "Epoch 14/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.9087 - accuracy: 0.6172\n",
      "Epoch 00014: val_loss improved from 0.99394 to 0.99194, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 124s 641ms/step - loss: 0.9085 - accuracy: 0.6174 - val_loss: 0.9919 - val_accuracy: 0.6027\n",
      "Epoch 15/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.8842 - accuracy: 0.6357\n",
      "Epoch 00015: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 129s 665ms/step - loss: 0.8838 - accuracy: 0.6360 - val_loss: 0.9932 - val_accuracy: 0.6220\n",
      "Epoch 16/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.8635 - accuracy: 0.6448\n",
      "Epoch 00016: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 126s 649ms/step - loss: 0.8635 - accuracy: 0.6445 - val_loss: 1.0371 - val_accuracy: 0.6027\n",
      "Epoch 17/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.8425 - accuracy: 0.6582\n",
      "Epoch 00017: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.8430 - accuracy: 0.6577 - val_loss: 1.0308 - val_accuracy: 0.5982\n",
      "Epoch 18/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.8251 - accuracy: 0.6603\n",
      "Epoch 00018: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 114s 586ms/step - loss: 0.8253 - accuracy: 0.6608 - val_loss: 1.0018 - val_accuracy: 0.5863\n",
      "Epoch 19/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.8262 - accuracy: 0.6595\n",
      "Epoch 00019: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 107s 554ms/step - loss: 0.8258 - accuracy: 0.6596 - val_loss: 1.0056 - val_accuracy: 0.6057\n",
      "Epoch 20/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7835 - accuracy: 0.6786\n",
      "Epoch 00020: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 107s 551ms/step - loss: 0.7839 - accuracy: 0.6783 - val_loss: 1.0187 - val_accuracy: 0.6086\n",
      "Epoch 21/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7720 - accuracy: 0.6894\n",
      "Epoch 00021: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 109s 563ms/step - loss: 0.7709 - accuracy: 0.6899 - val_loss: 1.0113 - val_accuracy: 0.6265\n",
      "Epoch 22/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7650 - accuracy: 0.6893\n",
      "Epoch 00022: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 109s 563ms/step - loss: 0.7653 - accuracy: 0.6891 - val_loss: 1.0618 - val_accuracy: 0.6161\n",
      "Epoch 23/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7394 - accuracy: 0.7050\n",
      "Epoch 00023: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 108s 556ms/step - loss: 0.7401 - accuracy: 0.7043 - val_loss: 1.0562 - val_accuracy: 0.6027\n",
      "Epoch 24/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7231 - accuracy: 0.7085\n",
      "Epoch 00024: val_loss did not improve from 0.99194\n",
      "194/194 [==============================] - 113s 583ms/step - loss: 0.7226 - accuracy: 0.7084 - val_loss: 1.0870 - val_accuracy: 0.6190\n",
      "Epoch 25/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.7120 - accuracy: 0.7160\n",
      "Epoch 00025: val_loss improved from 0.99194 to 0.99026, saving model to models/lstm.h5\n",
      "194/194 [==============================] - 119s 614ms/step - loss: 0.7114 - accuracy: 0.7160 - val_loss: 0.9903 - val_accuracy: 0.6369\n",
      "Epoch 26/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.6797 - accuracy: 0.7333\n",
      "Epoch 00026: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 118s 607ms/step - loss: 0.6797 - accuracy: 0.7328 - val_loss: 1.0853 - val_accuracy: 0.5982\n",
      "Epoch 27/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.7345\n",
      "Epoch 00027: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 120s 621ms/step - loss: 0.6773 - accuracy: 0.7345 - val_loss: 1.0455 - val_accuracy: 0.5997\n",
      "Epoch 28/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.6572 - accuracy: 0.7419\n",
      "Epoch 00028: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 121s 626ms/step - loss: 0.6565 - accuracy: 0.7426 - val_loss: 1.1079 - val_accuracy: 0.6131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.6346 - accuracy: 0.7594\n",
      "Epoch 00029: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 123s 632ms/step - loss: 0.6350 - accuracy: 0.7595 - val_loss: 1.0515 - val_accuracy: 0.5997\n",
      "Epoch 30/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.7701\n",
      "Epoch 00030: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 123s 637ms/step - loss: 0.6114 - accuracy: 0.7695 - val_loss: 1.0530 - val_accuracy: 0.6295\n",
      "Epoch 31/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5872 - accuracy: 0.7772\n",
      "Epoch 00031: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 123s 634ms/step - loss: 0.5873 - accuracy: 0.7775 - val_loss: 0.9998 - val_accuracy: 0.6533\n",
      "Epoch 32/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5821 - accuracy: 0.7801\n",
      "Epoch 00032: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 121s 625ms/step - loss: 0.5818 - accuracy: 0.7801 - val_loss: 1.0437 - val_accuracy: 0.6161\n",
      "Epoch 33/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5801 - accuracy: 0.7821\n",
      "Epoch 00033: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 159s 817ms/step - loss: 0.5798 - accuracy: 0.7822 - val_loss: 1.0200 - val_accuracy: 0.6235\n",
      "Epoch 34/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5601 - accuracy: 0.7855\n",
      "Epoch 00034: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 185s 952ms/step - loss: 0.5605 - accuracy: 0.7851 - val_loss: 1.0329 - val_accuracy: 0.6339\n",
      "Epoch 35/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5637 - accuracy: 0.7882\n",
      "Epoch 00035: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 123s 636ms/step - loss: 0.5637 - accuracy: 0.7882 - val_loss: 1.1352 - val_accuracy: 0.6369\n",
      "Epoch 36/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8020\n",
      "Epoch 00036: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 127s 656ms/step - loss: 0.5258 - accuracy: 0.8017 - val_loss: 1.0663 - val_accuracy: 0.6488\n",
      "Epoch 37/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.5195 - accuracy: 0.8083\n",
      "Epoch 00037: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 126s 650ms/step - loss: 0.5206 - accuracy: 0.8077 - val_loss: 1.0360 - val_accuracy: 0.6533\n",
      "Epoch 38/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4927 - accuracy: 0.8190\n",
      "Epoch 00038: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 125s 645ms/step - loss: 0.4928 - accuracy: 0.8188 - val_loss: 1.0886 - val_accuracy: 0.6250\n",
      "Epoch 39/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8196\n",
      "Epoch 00039: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 122s 628ms/step - loss: 0.4955 - accuracy: 0.8197 - val_loss: 1.1213 - val_accuracy: 0.6503\n",
      "Epoch 40/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4684 - accuracy: 0.8253\n",
      "Epoch 00040: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 124s 637ms/step - loss: 0.4682 - accuracy: 0.8251 - val_loss: 1.1341 - val_accuracy: 0.6458\n",
      "Epoch 41/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4703 - accuracy: 0.8255\n",
      "Epoch 00041: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 179s 921ms/step - loss: 0.4701 - accuracy: 0.8252 - val_loss: 1.1090 - val_accuracy: 0.6562\n",
      "Epoch 42/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8306\n",
      "Epoch 00042: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 152s 785ms/step - loss: 0.4635 - accuracy: 0.8301 - val_loss: 1.2184 - val_accuracy: 0.6324\n",
      "Epoch 43/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.8376\n",
      "Epoch 00043: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 133s 684ms/step - loss: 0.4475 - accuracy: 0.8376 - val_loss: 1.1091 - val_accuracy: 0.6458\n",
      "Epoch 44/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4675 - accuracy: 0.8255\n",
      "Epoch 00044: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 120s 620ms/step - loss: 0.4681 - accuracy: 0.8255 - val_loss: 1.1536 - val_accuracy: 0.6205\n",
      "Epoch 45/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4421 - accuracy: 0.8408\n",
      "Epoch 00045: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.4428 - accuracy: 0.8400 - val_loss: 1.1540 - val_accuracy: 0.6116\n",
      "Epoch 46/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8423\n",
      "Epoch 00046: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 115s 592ms/step - loss: 0.4383 - accuracy: 0.8420 - val_loss: 1.1214 - val_accuracy: 0.6473\n",
      "Epoch 47/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4145 - accuracy: 0.8544\n",
      "Epoch 00047: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 117s 604ms/step - loss: 0.4149 - accuracy: 0.8547 - val_loss: 1.1707 - val_accuracy: 0.6369\n",
      "Epoch 48/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8407\n",
      "Epoch 00048: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 116s 598ms/step - loss: 0.4268 - accuracy: 0.8410 - val_loss: 1.1539 - val_accuracy: 0.6518\n",
      "Epoch 49/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.3956 - accuracy: 0.8557\n",
      "Epoch 00049: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 123s 636ms/step - loss: 0.3955 - accuracy: 0.8558 - val_loss: 1.1815 - val_accuracy: 0.6235\n",
      "Epoch 50/50\n",
      "193/194 [============================>.] - ETA: 0s - loss: 0.4108 - accuracy: 0.8462\n",
      "Epoch 00050: val_loss did not improve from 0.99026\n",
      "194/194 [==============================] - 126s 650ms/step - loss: 0.4108 - accuracy: 0.8462 - val_loss: 1.2065 - val_accuracy: 0.6429\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "df = pd.read_csv('logs/log_history.csv')\n",
    "plt.title('LSTM', size=16)\n",
    "plt.plot(df.accuracy, color='c', label='train')\n",
    "plt.plot(df.val_accuracy, ls='--', color='c', label='Validation')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tick_params(axis='both', which='major', labelsize=12)\n",
    "plt.ylim([0,1.0])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
